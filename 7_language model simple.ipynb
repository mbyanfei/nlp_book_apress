{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code 39 to Code 45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.util import ngrams\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Language model is based on probability of words occurring together. There could be a pure frequency based approach or it there could be a recurrent neural network based sequence to sequence model used to correct the sentences coming out of the acoustic model. Below will see an example of building a language model using bigrams and probability distribution. We have taken few lines from wikipedia on natural language processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_text=open(\"nlp_text.txt\",\"r\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Natural language processing\\n\\n\\nAn automated online assistant providing customer service on a web page'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###print characters\n",
    "inp_text[0:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do some preprocessing and clean the text so that all words are normalized We could also remove stop words depending on the use case at hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_text = inp_text.lower()\n",
    "inp_text1 = re.sub('[^a-z/s]+',' ',inp_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'natural language processing an automated online assistant providing customer service on a web page an example of an application where natural language processing is a major component natural language processing nlp is a subfield of linguistics computer science information engineering and artificial intelligence concerned with the interactions between computers and human natural languages in particular how to program computers to process and analyze large amounts of natural language data challenges in natural language processing frequently involve speech recognition natural language understanding and natural language generation contents history rule based vs statistical nlp major evaluations and tasks syntax semantics discourse speech dialogue see also references further reading history the history of natural language processing nlp generally started in the s although work can be found from earlier periods in alan turing published an article titled computing machinery and intelligence w'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_text1[0:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting a corpus of bigram from the sentences. On building a language model, once we provide the word the model would output the most probable word following the given word. We could increase the n-grams to higher number for better precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_grams = ngrams(inp_text1.split(), 2)\n",
    "l1 = []\n",
    "for grams in n_grams :\n",
    "    l1.append((grams[0].lower(),grams[1].lower()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Language Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bigrams are now organzied as a dataframe with lead and lag words. So given lead word we will be getting the set of probable lag words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = pd.DataFrame(l1)\n",
    "df0.columns = [\"lead\",\"lag\"]\n",
    "\n",
    "lead_all = df0[\"lead\"].unique()\n",
    "lag_all = df0[\"lag\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lead_dict = {}\n",
    "for i in lead_all:\n",
    "    matches = df0.loc[df0.lead==i,\"lag\"]\n",
    "\n",
    "    len_mtch = len(matches)\n",
    "    lag_dict =  dict(Counter(matches))\n",
    "    \n",
    "\n",
    "    \n",
    "    for k in lag_dict:\n",
    "        lag_dict[k] = lag_dict[k]/len_mtch \n",
    "    \n",
    "\n",
    "    \n",
    "    lead_dict[i] = lag_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets test this for the word “laguage”. Below are the most probable words following the word “language”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'processing': 0.6666666666666666,\n",
       " 'data': 0.041666666666666664,\n",
       " 'understanding': 0.041666666666666664,\n",
       " 'generation': 0.041666666666666664,\n",
       " 'system': 0.041666666666666664,\n",
       " 'models': 0.041666666666666664,\n",
       " 'tasks': 0.041666666666666664,\n",
       " 'modeling': 0.08333333333333333}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lead_dict[\"language\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda2-py36]",
   "language": "python",
   "name": "conda-env-Anaconda2-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
